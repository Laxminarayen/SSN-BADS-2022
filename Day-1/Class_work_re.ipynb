{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled29.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGbVpWL7SEj4"
      },
      "outputs": [],
      "source": [
        "ssn = \"Datascience course\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ssn[4] = \"j\"\n",
        "#Strings are immutable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "iEcL82cZSYNJ",
        "outputId": "d54108d2-ccbc-4126-91ca-2e637f772c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-36475bd02407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mssn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"j\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Strings are stored as UTF-8 entities"
      ],
      "metadata": {
        "id": "Wxk1phkbSw2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Artimetics with strings\n",
        "#1. +\n",
        "print(\"ssn\"+\" sase\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6C7w_VeSwzo",
        "outputId": "33cd0a05-a9b6-40d0-fe75-0f49ea048647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssn sase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#* repeats the pattern\n",
        "text = \"hal\"\n",
        "print(text*10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWvrIYqZSwwg",
        "outputId": "4255dbd1-1bd8-4f93-e03b-4f354aa2a7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "halhalhalhalhalhalhalhalhalhal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello World!\"\n",
        "text.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5Q5kgI1jSiaS",
        "outputId": "ce6a950a-c2f6-42dd-f908-50264939c774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello world!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.upper()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4zimUoLOTyvS",
        "outputId": "e5d7724e-f426-41c6-cc36-6a3808a9c673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'HELLO WORLD!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.split('l')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffOpSRbqTypG",
        "outputId": "1514ea0c-9f26-493f-fb64-82efa2ab4c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He', '', 'o Wor', 'd!']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\",\".join([\"SSN\",\"School\",\"Adv\"]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AZ7e92TuVAeu",
        "outputId": "7ed74dd4-8e9c-491a-f760-d5bcaa62fd17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SSN,School,Adv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text_to_search = '''\n",
        "abcdefghijklmnopqurtuvwxyz\n",
        "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
        "1234567890\n",
        "Ha HaHa\n",
        "MetaCharacters (Need to be escaped):\n",
        ". ^ $ * + ? { } [ ] \\ | ( )\n",
        "https:\\\\www.github.com\n",
        "321-555-4321\n",
        "123.555.1234\n",
        "123*555*1234\n",
        "800-555-1234\n",
        "900-555-1234\n",
        "Mr. Schafer\n",
        "Mr Smith\n",
        "Ms Davis\n",
        "Mrs. Robinson\n",
        "Mr. T\n",
        "'''"
      ],
      "metadata": {
        "id": "0AOKTfu-VAcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\\d - digits[0-9] \\D- Not a digit(0-9)"
      ],
      "metadata": {
        "id": "hacLeKQIVAY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile('[0-9][0-9]')\n",
        "matches = pattern.finditer(text_to_search)"
      ],
      "metadata": {
        "id": "h-J1P1AIVAVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "id": "KMTmur7RVASf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#within square brackets - either or \n",
        "pattern = re.compile('[A-Za-z0-9_]')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "id": "Zwl69naHVAPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \\w - This is same as above - \\W\n",
        "pattern = re.compile('\\w')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "id": "oIq3CKRXeskn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#And inculding both cases\n",
        "pattern = re.compile('[A-Z][a-z]')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5Hh9kUZVAJY",
        "outputId": "af002a15-bf80-4e2d-845c-e030b97a756b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(66, 68), match='Ha'>\n",
            "<re.Match object; span=(69, 71), match='Ha'>\n",
            "<re.Match object; span=(71, 73), match='Ha'>\n",
            "<re.Match object; span=(74, 76), match='Me'>\n",
            "<re.Match object; span=(78, 80), match='Ch'>\n",
            "<re.Match object; span=(90, 92), match='Ne'>\n",
            "<re.Match object; span=(215, 217), match='Mr'>\n",
            "<re.Match object; span=(219, 221), match='Sc'>\n",
            "<re.Match object; span=(227, 229), match='Mr'>\n",
            "<re.Match object; span=(230, 232), match='Sm'>\n",
            "<re.Match object; span=(236, 238), match='Ms'>\n",
            "<re.Match object; span=(239, 241), match='Da'>\n",
            "<re.Match object; span=(245, 247), match='Mr'>\n",
            "<re.Match object; span=(250, 252), match='Ro'>\n",
            "<re.Match object; span=(259, 261), match='Mr'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#. - Match any character or a word except \\n\n",
        "pattern = re.compile('\\s')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tS-iCDdH9K",
        "outputId": "d8627cd6-0b1b-4a40-bcc7-37232187b175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(150, 162), match='321-555-4321'>\n",
            "<re.Match object; span=(163, 175), match='123.555.1234'>\n",
            "<re.Match object; span=(176, 188), match='123*555*1234'>\n",
            "<re.Match object; span=(189, 201), match='800-555-1234'>\n",
            "<re.Match object; span=(202, 214), match='900-555-1234'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#. - Match any character or a word except \\n\n",
        "pattern = re.compile('\\d\\d\\d.\\d\\d\\d.\\d\\d\\d\\d')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "id": "DIU0GgTRk3Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#. - Match any character or a word except \\n\n",
        "pattern = re.compile('\\d{3}.\\d\\d\\d.\\d{4}')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3GZ86DFmLIe",
        "outputId": "3ce8394a-74d6-4ee3-854b-659272ce9832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(161, 173), match='321-555-4321'>\n",
            "<re.Match object; span=(174, 186), match='123.555.1234'>\n",
            "<re.Match object; span=(187, 199), match='123*555*1234'>\n",
            "<re.Match object; span=(200, 212), match='800-555-1234'>\n",
            "<re.Match object; span=(213, 225), match='900-555-1234'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#. - Match any character or a word except \\n\n",
        "pattern = re.compile('[^A-Za-z]')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "id": "1r21kvvrmUfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#. - Match any character or a word except \\n\n",
        "pattern = re.compile('[A-Za-z]*')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "id": "SWAAcZjQnBVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "        'https://google.com',\n",
        "        'https://www.fb.com',\n",
        "        'http://someweb.com'\n",
        "]"
      ],
      "metadata": {
        "id": "GGyr-Oguo8CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#. - Match any character or a word except \\n\n",
        "pattern = re.compile('[A-Za-z]*')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw_BCiOanPZt",
        "outputId": "a42db30e-254b-489d-836e-74e0bc043088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 0), match=''>\n",
            "<re.Match object; span=(1, 27), match='abcdefghijklmnopqurtuvwxyz'>\n",
            "<re.Match object; span=(27, 27), match=''>\n",
            "<re.Match object; span=(28, 54), match='ABCDEFGHIJKLMNOPQRSTUVWXYZ'>\n",
            "<re.Match object; span=(54, 54), match=''>\n",
            "<re.Match object; span=(55, 55), match=''>\n",
            "<re.Match object; span=(56, 56), match=''>\n",
            "<re.Match object; span=(57, 57), match=''>\n",
            "<re.Match object; span=(58, 58), match=''>\n",
            "<re.Match object; span=(59, 59), match=''>\n",
            "<re.Match object; span=(60, 60), match=''>\n",
            "<re.Match object; span=(61, 61), match=''>\n",
            "<re.Match object; span=(62, 62), match=''>\n",
            "<re.Match object; span=(63, 63), match=''>\n",
            "<re.Match object; span=(64, 64), match=''>\n",
            "<re.Match object; span=(65, 65), match=''>\n",
            "<re.Match object; span=(66, 68), match='Ha'>\n",
            "<re.Match object; span=(68, 68), match=''>\n",
            "<re.Match object; span=(69, 73), match='HaHa'>\n",
            "<re.Match object; span=(73, 73), match=''>\n",
            "<re.Match object; span=(74, 88), match='MetaCharacters'>\n",
            "<re.Match object; span=(88, 88), match=''>\n",
            "<re.Match object; span=(89, 89), match=''>\n",
            "<re.Match object; span=(90, 94), match='Need'>\n",
            "<re.Match object; span=(94, 94), match=''>\n",
            "<re.Match object; span=(95, 97), match='to'>\n",
            "<re.Match object; span=(97, 97), match=''>\n",
            "<re.Match object; span=(98, 100), match='be'>\n",
            "<re.Match object; span=(100, 100), match=''>\n",
            "<re.Match object; span=(101, 108), match='escaped'>\n",
            "<re.Match object; span=(108, 108), match=''>\n",
            "<re.Match object; span=(109, 109), match=''>\n",
            "<re.Match object; span=(110, 110), match=''>\n",
            "<re.Match object; span=(111, 111), match=''>\n",
            "<re.Match object; span=(112, 112), match=''>\n",
            "<re.Match object; span=(113, 113), match=''>\n",
            "<re.Match object; span=(114, 114), match=''>\n",
            "<re.Match object; span=(115, 115), match=''>\n",
            "<re.Match object; span=(116, 116), match=''>\n",
            "<re.Match object; span=(117, 117), match=''>\n",
            "<re.Match object; span=(118, 118), match=''>\n",
            "<re.Match object; span=(119, 119), match=''>\n",
            "<re.Match object; span=(120, 120), match=''>\n",
            "<re.Match object; span=(121, 121), match=''>\n",
            "<re.Match object; span=(122, 122), match=''>\n",
            "<re.Match object; span=(123, 123), match=''>\n",
            "<re.Match object; span=(124, 124), match=''>\n",
            "<re.Match object; span=(125, 125), match=''>\n",
            "<re.Match object; span=(126, 126), match=''>\n",
            "<re.Match object; span=(127, 127), match=''>\n",
            "<re.Match object; span=(128, 128), match=''>\n",
            "<re.Match object; span=(129, 129), match=''>\n",
            "<re.Match object; span=(130, 130), match=''>\n",
            "<re.Match object; span=(131, 131), match=''>\n",
            "<re.Match object; span=(132, 132), match=''>\n",
            "<re.Match object; span=(133, 133), match=''>\n",
            "<re.Match object; span=(134, 134), match=''>\n",
            "<re.Match object; span=(135, 135), match=''>\n",
            "<re.Match object; span=(136, 136), match=''>\n",
            "<re.Match object; span=(137, 137), match=''>\n",
            "<re.Match object; span=(138, 138), match=''>\n",
            "<re.Match object; span=(139, 144), match='https'>\n",
            "<re.Match object; span=(144, 144), match=''>\n",
            "<re.Match object; span=(145, 145), match=''>\n",
            "<re.Match object; span=(146, 149), match='www'>\n",
            "<re.Match object; span=(149, 149), match=''>\n",
            "<re.Match object; span=(150, 156), match='github'>\n",
            "<re.Match object; span=(156, 156), match=''>\n",
            "<re.Match object; span=(157, 160), match='com'>\n",
            "<re.Match object; span=(160, 160), match=''>\n",
            "<re.Match object; span=(161, 161), match=''>\n",
            "<re.Match object; span=(162, 162), match=''>\n",
            "<re.Match object; span=(163, 163), match=''>\n",
            "<re.Match object; span=(164, 164), match=''>\n",
            "<re.Match object; span=(165, 165), match=''>\n",
            "<re.Match object; span=(166, 166), match=''>\n",
            "<re.Match object; span=(167, 167), match=''>\n",
            "<re.Match object; span=(168, 168), match=''>\n",
            "<re.Match object; span=(169, 169), match=''>\n",
            "<re.Match object; span=(170, 170), match=''>\n",
            "<re.Match object; span=(171, 171), match=''>\n",
            "<re.Match object; span=(172, 172), match=''>\n",
            "<re.Match object; span=(173, 173), match=''>\n",
            "<re.Match object; span=(174, 174), match=''>\n",
            "<re.Match object; span=(175, 175), match=''>\n",
            "<re.Match object; span=(176, 176), match=''>\n",
            "<re.Match object; span=(177, 177), match=''>\n",
            "<re.Match object; span=(178, 178), match=''>\n",
            "<re.Match object; span=(179, 179), match=''>\n",
            "<re.Match object; span=(180, 180), match=''>\n",
            "<re.Match object; span=(181, 181), match=''>\n",
            "<re.Match object; span=(182, 182), match=''>\n",
            "<re.Match object; span=(183, 183), match=''>\n",
            "<re.Match object; span=(184, 184), match=''>\n",
            "<re.Match object; span=(185, 185), match=''>\n",
            "<re.Match object; span=(186, 186), match=''>\n",
            "<re.Match object; span=(187, 187), match=''>\n",
            "<re.Match object; span=(188, 188), match=''>\n",
            "<re.Match object; span=(189, 189), match=''>\n",
            "<re.Match object; span=(190, 190), match=''>\n",
            "<re.Match object; span=(191, 191), match=''>\n",
            "<re.Match object; span=(192, 192), match=''>\n",
            "<re.Match object; span=(193, 193), match=''>\n",
            "<re.Match object; span=(194, 194), match=''>\n",
            "<re.Match object; span=(195, 195), match=''>\n",
            "<re.Match object; span=(196, 196), match=''>\n",
            "<re.Match object; span=(197, 197), match=''>\n",
            "<re.Match object; span=(198, 198), match=''>\n",
            "<re.Match object; span=(199, 199), match=''>\n",
            "<re.Match object; span=(200, 200), match=''>\n",
            "<re.Match object; span=(201, 201), match=''>\n",
            "<re.Match object; span=(202, 202), match=''>\n",
            "<re.Match object; span=(203, 203), match=''>\n",
            "<re.Match object; span=(204, 204), match=''>\n",
            "<re.Match object; span=(205, 205), match=''>\n",
            "<re.Match object; span=(206, 206), match=''>\n",
            "<re.Match object; span=(207, 207), match=''>\n",
            "<re.Match object; span=(208, 208), match=''>\n",
            "<re.Match object; span=(209, 209), match=''>\n",
            "<re.Match object; span=(210, 210), match=''>\n",
            "<re.Match object; span=(211, 211), match=''>\n",
            "<re.Match object; span=(212, 212), match=''>\n",
            "<re.Match object; span=(213, 213), match=''>\n",
            "<re.Match object; span=(214, 214), match=''>\n",
            "<re.Match object; span=(215, 215), match=''>\n",
            "<re.Match object; span=(216, 216), match=''>\n",
            "<re.Match object; span=(217, 217), match=''>\n",
            "<re.Match object; span=(218, 218), match=''>\n",
            "<re.Match object; span=(219, 219), match=''>\n",
            "<re.Match object; span=(220, 220), match=''>\n",
            "<re.Match object; span=(221, 221), match=''>\n",
            "<re.Match object; span=(222, 222), match=''>\n",
            "<re.Match object; span=(223, 223), match=''>\n",
            "<re.Match object; span=(224, 224), match=''>\n",
            "<re.Match object; span=(225, 225), match=''>\n",
            "<re.Match object; span=(226, 228), match='Mr'>\n",
            "<re.Match object; span=(228, 228), match=''>\n",
            "<re.Match object; span=(229, 229), match=''>\n",
            "<re.Match object; span=(230, 237), match='Schafer'>\n",
            "<re.Match object; span=(237, 237), match=''>\n",
            "<re.Match object; span=(238, 240), match='Mr'>\n",
            "<re.Match object; span=(240, 240), match=''>\n",
            "<re.Match object; span=(241, 246), match='Smith'>\n",
            "<re.Match object; span=(246, 246), match=''>\n",
            "<re.Match object; span=(247, 249), match='Ms'>\n",
            "<re.Match object; span=(249, 249), match=''>\n",
            "<re.Match object; span=(250, 255), match='Davis'>\n",
            "<re.Match object; span=(255, 255), match=''>\n",
            "<re.Match object; span=(256, 259), match='Mrs'>\n",
            "<re.Match object; span=(259, 259), match=''>\n",
            "<re.Match object; span=(260, 260), match=''>\n",
            "<re.Match object; span=(261, 269), match='Robinson'>\n",
            "<re.Match object; span=(269, 269), match=''>\n",
            "<re.Match object; span=(270, 272), match='Mr'>\n",
            "<re.Match object; span=(272, 272), match=''>\n",
            "<re.Match object; span=(273, 273), match=''>\n",
            "<re.Match object; span=(274, 275), match='T'>\n",
            "<re.Match object; span=(275, 275), match=''>\n",
            "<re.Match object; span=(276, 276), match=''>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'^'\n",
        "#. - Match any character or a word except \\n\n",
        "pattern = re.compile(r'^[A-Z]')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "id": "khyC445clDsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\t')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo0Us0rtdYvR",
        "outputId": "3f03834a-3450-4a9b-b1e5-f00c26fde908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r'')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52LNoqDadfsc",
        "outputId": "157cb0d2-e6da-44b0-cb39-9b5f76899b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\\w - all word characters [0-9, A-Z, a-z, _]"
      ],
      "metadata": {
        "id": "tAwY__oBbwi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile('Mr\\.?\\s([A-Z])([A-Za-z])*')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXGk3_YepnBk",
        "outputId": "9934fde9-8642-4f40-9b58-784cf1b43466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(226, 237), match='Mr. Schafer'>\n",
            "<re.Match object; span=(238, 246), match='Mr Smith'>\n",
            "<re.Match object; span=(270, 275), match='Mr. T'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile('([\\w.-]+)(@[A-Za-z])+(\\.\\w+)')\n",
        "with open('data.txt','r',encoding ='utf-8') as f:\n",
        "  lines = f.read()\n",
        "  matches = pattern.finditer(lines)\n",
        "  for match in matches: \n",
        "    print(match.group(2)+match.group(3))\n"
      ],
      "metadata": {
        "id": "iAYLdJizpq3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = text_to_search.split('\\n')"
      ],
      "metadata": {
        "id": "PFngH0Y0tkpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#^-starts with \n",
        "#$ - Ends with \n",
        "pattern = re.compile(\"^M\\w+\")\n",
        "for i in text_list:\n",
        "  matches = pattern.finditer(i)\n",
        "  for match in matches: \n",
        "    print(match)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz34llQey-KB",
        "outputId": "5b81ef5f-6034-418e-a424-e9bc13bf0a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 14), match='MetaCharacters'>\n",
            "<re.Match object; span=(0, 2), match='Mr'>\n",
            "<re.Match object; span=(0, 2), match='Mr'>\n",
            "<re.Match object; span=(0, 2), match='Ms'>\n",
            "<re.Match object; span=(0, 3), match='Mrs'>\n",
            "<re.Match object; span=(0, 2), match='Mr'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(\"\\w+.\\w+.\\w+m$\")\n",
        "for i in text_list:\n",
        "  matches = pattern.finditer(i)\n",
        "  for match in matches: \n",
        "    print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Y51U8Pzcpq",
        "outputId": "e2a0bb67-68f9-4c6c-d5eb-96d049296da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(7, 21), match='www.github.com'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile('(Mr|Mrs|Ms)\\.?\\s([A-Z])([A-Za-z])*')\n",
        "matches = pattern.finditer(text_to_search)\n",
        "for match in matches: \n",
        "  print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X7WdGhO0Fxh",
        "outputId": "dae07ffa-e2f3-4e18-9401-221aec370bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(226, 237), match='Mr. Schafer'>\n",
            "<re.Match object; span=(238, 246), match='Mr Smith'>\n",
            "<re.Match object; span=(247, 255), match='Ms Davis'>\n",
            "<re.Match object; span=(256, 269), match='Mrs. Robinson'>\n",
            "<re.Match object; span=(270, 275), match='Mr. T'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "dnScby140fxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def laxmi(text):\n",
        "  '''\n",
        "  this is a fn that converts strings to lower\n",
        "  '''\n",
        "  return text.lower()"
      ],
      "metadata": {
        "id": "5aucVGEo2eSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpqwvlE_298q",
        "outputId": "67e956e2-bf84-4da7-f52e-c2964b75118d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/extended_omw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2021.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"Ssn SASE is good. It is one of the best places to read DS\""
      ],
      "metadata": {
        "id": "rWt46KdG1fPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.sent_tokenize(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNoWUmkY1fJ4",
        "outputId": "65e07cdf-2dbd-4f75-f5ba-311fa32635a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ssn SASE is good.', 'It is one of the best places to read DS']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "laxmi?"
      ],
      "metadata": {
        "id": "JxqS1I1U1fCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CeQExY5m2rSc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}